{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import art#fully initialise module\n",
    "from art.estimators.classification import SklearnClassifier\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnDecisionTreeClassifier\n",
    "from art.attacks.evasion import DecisionTreeAttack\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "data=pd.read_csv('dataset.csv')\n",
    "\n",
    "# clean up column names\n",
    "\n",
    "data.columns = data.columns.\\\n",
    "    str.strip().\\\n",
    "    str.lower()\n",
    "\n",
    "#____remove non-numeric columns\n",
    "    \n",
    "data = data.select_dtypes(['number']) \n",
    "\n",
    "\n",
    "#__extracting dependent and independent variable\n",
    "\n",
    "x=data.drop(['type'],axis=1)\n",
    "y=data['type']\n",
    "x=np.nan_to_num(x) #____replace nan with zero and inf with finite numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#______Splitting the data into Training and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=1/3,random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc=RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(x_train,y_train)\n",
    "\n",
    "pred1=rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Forest accuracy score is  0.9579124579124579\n",
      "For Random Forest confusion_matrix is: \n",
      "\n",
      " [[506   8]\n",
      " [ 17  63]]\n",
      "For Random Forest Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       514\n",
      "           1       0.89      0.79      0.83        80\n",
      "\n",
      "    accuracy                           0.96       594\n",
      "   macro avg       0.93      0.89      0.91       594\n",
      "weighted avg       0.96      0.96      0.96       594\n",
      "\n",
      "False Positive Rate: 0.01556420233463035\n"
     ]
    }
   ],
   "source": [
    "#accuracy for random forest\n",
    "print('For Random Forest accuracy score is ',accuracy_score(y_test,pred1))\n",
    "print('For Random Forest confusion_matrix is: \\n\\n',confusion_matrix(y_test,pred1))\n",
    "print ('For Random Forest Classification Report: \\n\\n',classification_report(y_test,pred1))\n",
    "false_positive_rate=confusion_matrix(y_test,pred1)[0][1]/(confusion_matrix(y_test,pred1)[0][0]+confusion_matrix(y_test,pred1)[0][1])\n",
    "print(\"False Positive Rate: \"+str(false_positive_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decision tree attack: 100%|██████████████████████████████████████████████████████| 1187/1187 [00:00<00:00, 3090.99it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "model.fit(X=x_train, y=y_train)\n",
    "\n",
    "# Create ART classifier for scikit-learn GradientBoostingClassifier\n",
    "art_classifier = ScikitlearnDecisionTreeClassifier(model=model)\n",
    "\n",
    "# Create ART Zeroth Order Optimization attack\n",
    "dta = DecisionTreeAttack(art_classifier)#art_classifier,offset=20.0)\n",
    "\n",
    "# Generate adversarial samples with ART Zeroth Order Optimization attack\n",
    "x_train_adv = dta.generate(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.9000000e+01, 8.4990000e+00, 3.2400000e+02, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [4.8000000e+01, 1.1000000e+01, 6.4000000e+02, ..., 3.4940000e+03,\n",
       "        3.1000000e+01, 8.0000000e+00],\n",
       "       [6.1000000e+01, 8.4990000e+00, 3.3425999e+04, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       ...,\n",
       "       [6.0000000e+01, 1.1000000e+01, 0.0000000e+00, ..., 5.3920000e+03,\n",
       "        3.5000000e+01, 7.0010000e+00],\n",
       "       [4.6000000e+01, 9.0000000e+00, 0.0000000e+00, ..., 5.6400000e+02,\n",
       "        6.0000000e+00, 7.0010000e+00],\n",
       "       [7.5000000e+01, 1.6000000e+01, 0.0000000e+00, ..., 4.2470000e+03,\n",
       "        4.1000000e+01, 6.9990000e+00]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.9000e+01, 9.0000e+00, 3.2400e+02, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [4.8000e+01, 1.1000e+01, 6.4000e+02, ..., 3.4940e+03, 3.1000e+01,\n",
       "        8.0000e+00],\n",
       "       [6.1000e+01, 1.2000e+01, 3.9198e+04, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       ...,\n",
       "       [6.0000e+01, 1.1000e+01, 0.0000e+00, ..., 5.3920e+03, 3.5000e+01,\n",
       "        6.0000e+00],\n",
       "       [4.6000e+01, 9.0000e+00, 0.0000e+00, ..., 5.6400e+02, 6.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [7.5000e+01, 1.6000e+01, 0.0000e+00, ..., 4.2470e+03, 4.1000e+01,\n",
       "        8.0000e+00]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decision tree attack: 100%|████████████████████████████████████████████████████████| 594/594 [00:00<00:00, 3070.16it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test_adv = dta.generate(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1000e+01, 1.0000e+01, 0.0000e+00, ..., 5.0930e+03, 4.1000e+01,\n",
       "        7.0010e+00],\n",
       "       [5.6000e+01, 9.0000e+00, 0.0000e+00, ..., 2.4160e+03, 2.1000e+01,\n",
       "        7.0010e+00],\n",
       "       [1.2800e+02, 3.5001e+01, 2.9840e+04, ..., 4.3200e+02, 4.0000e+00,\n",
       "        0.0000e+00],\n",
       "       ...,\n",
       "       [4.9000e+01, 9.0000e+00, 1.6200e+02, ..., 2.1380e+03, 2.5000e+01,\n",
       "        7.0010e+00],\n",
       "       [4.8000e+01, 1.0000e+01, 3.4500e+02, ..., 1.4740e+03, 1.9000e+01,\n",
       "        7.0010e+00],\n",
       "       [6.5000e+01, 1.1000e+01, 1.2339e+04, ..., 1.9220e+03, 2.2000e+01,\n",
       "        7.0010e+00]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1000e+01, 1.0000e+01, 0.0000e+00, ..., 5.0930e+03, 4.1000e+01,\n",
       "        6.0000e+00],\n",
       "       [5.6000e+01, 9.0000e+00, 0.0000e+00, ..., 2.4160e+03, 2.1000e+01,\n",
       "        6.0000e+00],\n",
       "       [1.2800e+02, 2.5000e+01, 2.9840e+04, ..., 4.3200e+02, 4.0000e+00,\n",
       "        0.0000e+00],\n",
       "       ...,\n",
       "       [4.9000e+01, 9.0000e+00, 1.6200e+02, ..., 2.1380e+03, 2.5000e+01,\n",
       "        6.0000e+00],\n",
       "       [4.8000e+01, 1.0000e+01, 3.4500e+02, ..., 1.4740e+03, 1.9000e+01,\n",
       "        2.0000e+00],\n",
       "       [6.5000e+01, 1.1000e+01, 1.2339e+04, ..., 1.9220e+03, 2.2000e+01,\n",
       "        4.0000e+00]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign Training Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "score = model.score(x_train, y_train)\n",
    "print(\"Benign Training Score: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Training Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "score = model.score(x_train_adv, y_train) #simply to see if they are matching or not\n",
    "print(\"Adversarial Training Score: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign Test Score: 0.9327\n"
     ]
    }
   ],
   "source": [
    "score = model.score(x_test, y_test)\n",
    "print(\"Benign Test Score: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Test Score: 0.0673\n"
     ]
    }
   ],
   "source": [
    "score = model.score(x_test_adv, y_test) #not necessary\n",
    "print(\"Adversarial Test Score: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For RandomForestClassifier accuracy score is  0.8956228956228957\n",
      "For RandomForestClassifier confusion_matrix is: \n",
      "\n",
      " [[486  28]\n",
      " [ 34  46]]\n",
      "For RandomForestClassifier Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       514\n",
      "           1       0.62      0.57      0.60        80\n",
      "\n",
      "    accuracy                           0.90       594\n",
      "   macro avg       0.78      0.76      0.77       594\n",
      "weighted avg       0.89      0.90      0.89       594\n",
      "\n",
      "False Negative Rate: 0.425\n"
     ]
    }
   ],
   "source": [
    "#GradientBoostingClassifier #how model handles data when trained on adversarial data, does noise mess things up?\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc=RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(x_train_adv,y_train)\n",
    "\n",
    "pred1=rfc.predict(x_test)\n",
    "\n",
    "#accuracy for RandomForestClassifier\n",
    "print('For RandomForestClassifier accuracy score is ',accuracy_score(y_test,pred1))\n",
    "print('For RandomForestClassifier confusion_matrix is: \\n\\n',confusion_matrix(y_test,pred1))\n",
    "print ('For RandomForestClassifier Classification Report: \\n\\n',classification_report(y_test,pred1))\n",
    "false_positive_rate=confusion_matrix(y_test,pred1)[1][0]/(confusion_matrix(y_test,pred1)[1][0]+confusion_matrix(y_test,pred1)[1][1])\n",
    "print(\"False Negative Rate: \"+str(false_positive_rate))#actually false negative rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For RandomForestClassifier accuracy score is  0.9410774410774411\n",
      "For RandomForestClassifier confusion_matrix is: \n",
      "\n",
      " [[510   4]\n",
      " [ 31  49]]\n",
      "For RandomForestClassifier Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97       514\n",
      "           1       0.92      0.61      0.74        80\n",
      "\n",
      "    accuracy                           0.94       594\n",
      "   macro avg       0.93      0.80      0.85       594\n",
      "weighted avg       0.94      0.94      0.94       594\n",
      "\n",
      "False Negative Rate: 0.3875\n"
     ]
    }
   ],
   "source": [
    "#GradientBoostingClassifier  #how model handles adversarial data, without adversarial training\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc=RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(x_train,y_train)\n",
    "\n",
    "pred1=rfc.predict(x_test_adv)\n",
    "\n",
    "#accuracy for RandomForestClassifier\n",
    "print('For RandomForestClassifier accuracy score is ',accuracy_score(y_test,pred1))\n",
    "print('For RandomForestClassifier confusion_matrix is: \\n\\n',confusion_matrix(y_test,pred1))\n",
    "print ('For RandomForestClassifier Classification Report: \\n\\n',classification_report(y_test,pred1))\n",
    "false_positive_rate=confusion_matrix(y_test,pred1)[1][0]/(confusion_matrix(y_test,pred1)[1][0]+confusion_matrix(y_test,pred1)[1][1])\n",
    "print(\"False Negative Rate: \"+str(false_positive_rate)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For RandomForestClassifier accuracy score is  0.9595959595959596\n",
      "For RandomForestClassifier confusion_matrix is: \n",
      "\n",
      " [[507   7]\n",
      " [ 17  63]]\n",
      "For RandomForestClassifier Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       514\n",
      "           1       0.90      0.79      0.84        80\n",
      "\n",
      "    accuracy                           0.96       594\n",
      "   macro avg       0.93      0.89      0.91       594\n",
      "weighted avg       0.96      0.96      0.96       594\n",
      "\n",
      "False Negative Rate: 0.2125\n"
     ]
    }
   ],
   "source": [
    "#GradientBoostingClassifier  #how model handles regular data, trained regularly\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc=RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(x_train,y_train)\n",
    "\n",
    "pred1=rfc.predict(x_test)\n",
    "\n",
    "#accuracy for RandomForestClassifier\n",
    "print('For RandomForestClassifier accuracy score is ',accuracy_score(y_test,pred1))\n",
    "print('For RandomForestClassifier confusion_matrix is: \\n\\n',confusion_matrix(y_test,pred1))\n",
    "print ('For RandomForestClassifier Classification Report: \\n\\n',classification_report(y_test,pred1))\n",
    "false_positive_rate=confusion_matrix(y_test,pred1)[1][0]/(confusion_matrix(y_test,pred1)[1][0]+confusion_matrix(y_test,pred1)[1][1])\n",
    "print(\"False Negative Rate: \"+str(false_positive_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For RandomForestClassifier accuracy score is  0.9427609427609428\n",
      "For RandomForestClassifier confusion_matrix is: \n",
      "\n",
      " [[495  19]\n",
      " [ 15  65]]\n",
      "For RandomForestClassifier Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       514\n",
      "           1       0.77      0.81      0.79        80\n",
      "\n",
      "    accuracy                           0.94       594\n",
      "   macro avg       0.87      0.89      0.88       594\n",
      "weighted avg       0.94      0.94      0.94       594\n",
      "\n",
      "False Negative Rate: 0.1875\n"
     ]
    }
   ],
   "source": [
    "#GradientBoostingClassifier #correct final model, that is how it handles adversarial data, after adversarial training\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc=RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(x_train_adv,y_train)\n",
    "\n",
    "pred1=rfc.predict(x_test_adv)\n",
    "\n",
    "#accuracy for RandomForestClassifier\n",
    "print('For RandomForestClassifier accuracy score is ',accuracy_score(y_test,pred1))\n",
    "print('For RandomForestClassifier confusion_matrix is: \\n\\n',confusion_matrix(y_test,pred1))\n",
    "print ('For RandomForestClassifier Classification Report: \\n\\n',classification_report(y_test,pred1))\n",
    "false_positive_rate=confusion_matrix(y_test,pred1)[1][0]/(confusion_matrix(y_test,pred1)[1][0]+confusion_matrix(y_test,pred1)[1][1])\n",
    "print(\"False Negative Rate: \"+str(false_positive_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test_adv[0:1, :])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[0:1, :])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
